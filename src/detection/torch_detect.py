import cv2
import numpy as np
import time
import serial

# --- –ù–ê–°–¢–†–û–ô–ö–ò SERIAL ---
SERIAL_PORT = '/dev/ttyACM0' 
BAUD_RATE = 9600

try:
    ser = serial.Serial(SERIAL_PORT, BAUD_RATE, timeout=0.1)
    time.sleep(2) 
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ {SERIAL_PORT}")
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
    ser = None

# --- –ù–ê–°–¢–†–û–ô–ö–ò –ú–û–î–ï–õ–ò ---
net = cv2.dnn.readNetFromONNX("/home/stefano/Documents/ATS_nto (copy)/src/detection/models/best.onnx")
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_DEFAULT)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL)

cap = cv2.VideoCapture(0)
FRAME_W = 640
FRAME_H = 480
cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_W)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_H)
TOTAL_AREA = FRAME_W * FRAME_H

last_sent_speed = -1

while True:
    ret, frame = cap.read()
    if not ret: break

    # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥
    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (640, 640), swapRB=True, crop=False)
    net.setInput(blob)
    outputs = net.forward()
    outputs = np.array([cv2.transpose(outputs[0])])
    
    rows = outputs[0].shape[0]
    boxes, confidences = [], []
    x_factor, y_factor = FRAME_W / 640, FRAME_H / 640

    max_person_area_pct = 0 # –ü—Ä–æ—Ü–µ–Ω—Ç –ø–ª–æ—â–∞–¥–∏ —Å–∞–º–æ–≥–æ "–±–æ–ª—å—à–æ–≥–æ" —á–µ–ª–æ–≤–µ–∫–∞

    for i in range(rows):
        prob = outputs[0][i][4]
        if prob >= 0.4:
            x, y, w, h = outputs[0][i][0:4]
            
            # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏
            left = int((x - 0.5 * w) * x_factor)
            top = int((y - 0.5 * h) * y_factor)
            width = int(w * x_factor)
            height = int(h * y_factor)
            
            boxes.append([left, top, width, height])
            confidences.append(float(prob))
            
            # –°—á–∏—Ç–∞–µ–º –ø–ª–æ—â–∞–¥—å —Ç–µ–∫—É—â–µ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –≤ % –æ—Ç –∫–∞–¥—Ä–∞
            current_area_pct = (width * height) / TOTAL_AREA * 100
            if current_area_pct > max_person_area_pct:
                max_person_area_pct = current_area_pct

    # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö (NMS —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–º–∫–∏)
    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.4, 0.4)
    if len(indices) > 0:
        for i in indices.flatten():
            b = boxes[i]
            # –¢–æ–Ω–∫–∞—è —Ä–∞–º–∫–∞ (thickness=1)
            cv2.rectangle(frame, (b[0], b[1]), (b[0]+b[2], b[1]+b[3]), (0, 255, 0), 1)

    # --- –õ–û–ì–ò–ö–ê –°–ö–û–†–û–°–¢–ò ---
    if max_person_area_pct == 0:
        # –õ—é–¥–µ–π –Ω–µ—Ç - –µ–¥–µ–º –±—ã—Å—Ç—Ä–æ
        current_speed = 100
    elif max_person_area_pct >= 5:
        # –ß–µ–ª–æ–≤–µ–∫ —Å–ª–∏—à–∫–æ–º –±–ª–∏–∑–∫–æ (–∑–∞–Ω–∏–º–∞–µ—Ç > 40% –∫–∞–¥—Ä–∞)
        current_speed = 0
    elif max_person_area_pct <= 0.5:
        # –ß–µ–ª–æ–≤–µ–∫ –æ—á–µ–Ω—å –¥–∞–ª–µ–∫–æ
        current_speed = 100
    else:
        # –ü–ª–∞–≤–Ω–æ–µ –∑–∞–º–µ–¥–ª–µ–Ω–∏–µ –æ—Ç 5% –¥–æ 40% –ø–ª–æ—â–∞–¥–∏
        # –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è: –µ—Å–ª–∏ 5% -> 100, –µ—Å–ª–∏ 40% -> 0
        interp = (max_person_area_pct - 0.3) / (6 - 0.3) # –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç 0.0 –¥–æ 1.0
        current_speed = int(100 * (1 - interp))

    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
    current_speed = max(0, min(100, current_speed))

    # --- –û–¢–ü–†–ê–í–ö–ê –í SERIAL ---
    if ser and current_speed != last_sent_speed:
        try:
            ser.write(f"{current_speed}\n".encode('utf-8'))
            last_sent_speed = current_speed
        except Exception as e:
            print(f"üì° –û—à–∏–±–∫–∞ —Å–≤—è–∑–∏: {e}")

    # –ò–Ω—Ñ–æ –Ω–∞ —ç–∫—Ä–∞–Ω–µ
    cv2.putText(frame, f"Speed: {current_speed} | Area: {max_person_area_pct:.1f}%", (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    cv2.imshow("Smart Detection", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'): break

if ser:
    ser.write(f"0\n".encode('utf-8'))
    ser.close()
cap.release()
cv2.destroyAllWindows()